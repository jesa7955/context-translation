{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodecoder_test_0  nodecoder_train_0  nodecoder_val_0  test_0  train_0  valid_0\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../resources/context_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s ../context_nmt ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"/home/litong/context_translation/resources/test_3c5cba7d2f64b7fb2d6b5013adc7a888.pkl\"\n",
    "train_path = \"/home/litong/context_translation/resources/train_aeabd4a49ce40d291d72fb22e4f84f70.pkl\"\n",
    "valid_path = \"/home/litong/context_translation/resources/valid_93dd7f59179d59481dffa319f8eceadb.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "from context_nmt.data.dataset_readers.context_translation_dataset_reader import read_context_index_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_path, 'rb') as source:\n",
    "    test_data = pickle.load(source)\n",
    "with open(valid_path, 'rb') as source:\n",
    "    valid_data = pickle.load(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(data, context_pairs, lang=\"en\"):\n",
    "    def get_pair(doc_id, sent_id):\n",
    "        context_index = context_pairs[doc_id][sent_id][0]\n",
    "        if context_index == -1:\n",
    "            context = \"\"\n",
    "        else:\n",
    "            context = data[doc_id][lang][context_index]\n",
    "        sent = data[doc_id][lang][sent_id]\n",
    "        return (context_index, sent_id, context, sent)\n",
    "    pairs = []\n",
    "    for doc_id, doc in data.items():\n",
    "        for sent_id, score in doc[\"pairs\"]:\n",
    "            pairs.append(get_pair(doc_id, sent_id))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_valid_cp = read_context_index_file('../resources/context_filter/nodecoder_val_0')\n",
    "nd_valid_pairs = get_pairs(valid_data, nd_valid_cp)\n",
    "nd_test_cp = read_context_index_file('../resources/context_filter/nodecoder_test_0')\n",
    "nd_test_pairs = get_pairs(test_data, nd_test_cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_cp = read_context_index_file('../resources/context_filter/valid_0')\n",
    "valid_pairs = get_pairs(valid_data, valid_cp)\n",
    "test_cp = read_context_index_file('../resources/context_filter/test_0')\n",
    "test_pairs = get_pairs(test_data, test_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_indexs = [random.randint(0, len(nd_valid_pairs)) for _ in range(10)]\n",
    "test_indexs = [random.randint(0, len(nd_test_pairs)) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[104, 898, 1656, 1716, 653, 111, 1383, 1266, 42, 798]\n",
      "[1777, 1524, 1308, 1514, 1543, 1731, 1642, 1238, 230, 460]\n"
     ]
    }
   ],
   "source": [
    "print(val_indexs)\n",
    "print(test_indexs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "979\n",
      "2051\n"
     ]
    }
   ],
   "source": [
    "print(sum([valid[0] != nd_valid[0] for valid, nd_valid in zip(valid_pairs, nd_valid_pairs)]))\n",
    "print(len(valid_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019\n",
      "2120\n"
     ]
    }
   ],
   "source": [
    "print(sum([test[0] != nd_test[0] for test, nd_test in zip(test_pairs, nd_test_pairs)]))\n",
    "print(len(test_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function corpus_bleu in module sacrebleu:\n",
      "\n",
      "corpus_bleu(sys_stream: Union[str, Iterable[str]], ref_streams: Union[str, List[Iterable[str]]], smooth_method='exp', smooth_value=0.0, force=False, lowercase=False, tokenize='13a', use_effective_order=False) -> sacrebleu.BLEU\n",
      "    Produces BLEU scores along with its sufficient statistics from a source against one or more references.\n",
      "    \n",
      "    :param sys_stream: The system stream (a sequence of segments)\n",
      "    :param ref_streams: A list of one or more reference streams (each a sequence of segments)\n",
      "    :param smooth: The smoothing method to use\n",
      "    :param smooth_value: For 'floor' smoothing, the floor to use\n",
      "    :param force: Ignore data that looks already tokenized\n",
      "    :param lowercase: Lowercase the data\n",
      "    :param tokenize: The tokenizer to use\n",
      "    :return: a BLEU object containing everything you'd want\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sacrebleu.corpus_bleu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
